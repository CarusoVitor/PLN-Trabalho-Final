{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/aprix-\n",
      "[nltk_data]     vitor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2226 entries, 0 to 2225\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        2226 non-null   object\n",
      " 1   text      2226 non-null   object\n",
      " 2   Anger     2226 non-null   int64 \n",
      " 3   Disgust   2226 non-null   int64 \n",
      " 4   Fear      2226 non-null   int64 \n",
      " 5   Joy       2226 non-null   int64 \n",
      " 6   Sadness   2226 non-null   int64 \n",
      " 7   Surprise  2226 non-null   int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "file = 'public_data/train/track_a/ptbr.csv'\n",
    "train = pd.read_csv(file)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptbr_train_track_a_00001</td>\n",
       "      <td>minha vó me disse que era frango e eu comi, ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptbr_train_track_a_00002</td>\n",
       "      <td>Está e a nossa deputada Benedita linda guerrei...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptbr_train_track_a_00003</td>\n",
       "      <td>só falta as roupas kkkkkkkkkkk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptbr_train_track_a_00004</td>\n",
       "      <td>Eu tmb. Comecei a sair de casa agora (fui pela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptbr_train_track_a_00005</td>\n",
       "      <td>Peço a Deus que nossos dirigentes tenham realm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  ptbr_train_track_a_00001   \n",
       "1  ptbr_train_track_a_00002   \n",
       "2  ptbr_train_track_a_00003   \n",
       "3  ptbr_train_track_a_00004   \n",
       "4  ptbr_train_track_a_00005   \n",
       "\n",
       "                                                text  Anger  Disgust  Fear  \\\n",
       "0  minha vó me disse que era frango e eu comi, ti...      0        0     0   \n",
       "1  Está e a nossa deputada Benedita linda guerrei...      0        0     0   \n",
       "2                     só falta as roupas kkkkkkkkkkk      0        0     0   \n",
       "3  Eu tmb. Comecei a sair de casa agora (fui pela...      0        0     0   \n",
       "4  Peço a Deus que nossos dirigentes tenham realm...      0        0     0   \n",
       "\n",
       "   Joy  Sadness  Surprise  \n",
       "0    0        1         0  \n",
       "1    1        0         0  \n",
       "2    1        0         0  \n",
       "3    0        1         0  \n",
       "4    0        0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados\n",
    "1. Case folding\n",
    "2. Remover stop words\n",
    "3. Remover acentuação e pontuação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'às',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"clean_text\"] = train[\"text\"].copy()\n",
    "# Case folding\n",
    "train[\"clean_text\"] = train[\"clean_text\"].str.lower()\n",
    "# Remover stopwords\n",
    "train[\"clean_text\"] = train[\"clean_text\"].replace({r\"\\b\" + stopword + r\"\\b\": \"\" for stopword in stopwords}, regex=True)\n",
    "# Remover acentuação e pontuação\n",
    "train[\"clean_text\"] = train[\"clean_text\"].str.replace(r\"[\\.!?\\\\\\-.,]\", \"\", regex=True)\n",
    "train[\"clean_text\"] = train[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       minha vó me disse que era frango e eu comi, ti...\n",
       " 1       Está e a nossa deputada Benedita linda guerrei...\n",
       " 2                          só falta as roupas kkkkkkkkkkk\n",
       " 3       Eu tmb. Comecei a sair de casa agora (fui pela...\n",
       " 4       Peço a Deus que nossos dirigentes tenham realm...\n",
       "                               ...                        \n",
       " 2221              Eu acho que o CAP vai surpreender hein.\n",
       " 2222    23:59 - Lula sabia de toda a corrupção no seu ...\n",
       " 2223    O Brasil precisa URGENTE de pessoas sérias e c...\n",
       " 2224    Sera que só eu acho que ta passando da hora de...\n",
       " 2225                                     falta só 2 porra\n",
       " Name: text, Length: 2226, dtype: object,\n",
       " 0         vó disse frango comi gosto frango mto inocente \n",
       " 1        deputada benedita linda guerreira parabéns ju...\n",
       " 2                                falta roupas kkkkkkkkkkk\n",
       " 3        tmb comecei sair casa agora ( primeira vez ci...\n",
       " 4       peço deus dirigentes realmente iluminação toma...\n",
       "                               ...                        \n",
       " 2221                        acho cap vai surpreender hein\n",
       " 2222    23:59 lula sabia toda corrupção governo 00:00 ...\n",
       " 2223     brasil precisa urgente pessoas sérias comprom...\n",
       " 2224    sera acho ta passando hora impeachment pra tir...\n",
       " 2225                                        falta 2 porra\n",
       " Name: clean_text, Length: 2226, dtype: object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"text\"], train[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionar emoção neutra\n",
    "\n",
    "Para casos que não tem nenhuma emoção na linha, adicionamos uma nova emoção: neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_EMOTIONS = [\"Anger\", \"Disgust\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "\n",
    "train[\"Neutral\"] = 0\n",
    "no_emotions_mask = train[BASE_EMOTIONS].sum(axis=1) == 0\n",
    "train.loc[no_emotions_mask, \"Neutral\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aprix-vitor/.cache/pypoetry/virtualenvs/pln-trabalho-final-A9EDKhyv-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln-trabalho-final-A9EDKhyv-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
