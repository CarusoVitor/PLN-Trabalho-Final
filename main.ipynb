{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vitor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2226 entries, 0 to 2225\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        2226 non-null   object\n",
      " 1   text      2226 non-null   object\n",
      " 2   Anger     2226 non-null   int64 \n",
      " 3   Disgust   2226 non-null   int64 \n",
      " 4   Fear      2226 non-null   int64 \n",
      " 5   Joy       2226 non-null   int64 \n",
      " 6   Sadness   2226 non-null   int64 \n",
      " 7   Surprise  2226 non-null   int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "file = 'public_data/train/track_a/ptbr.csv'\n",
    "data = pd.read_csv(file)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Disgust</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptbr_train_track_a_00001</td>\n",
       "      <td>minha vó me disse que era frango e eu comi, ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ptbr_train_track_a_00002</td>\n",
       "      <td>Está e a nossa deputada Benedita linda guerrei...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptbr_train_track_a_00003</td>\n",
       "      <td>só falta as roupas kkkkkkkkkkk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ptbr_train_track_a_00004</td>\n",
       "      <td>Eu tmb. Comecei a sair de casa agora (fui pela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ptbr_train_track_a_00005</td>\n",
       "      <td>Peço a Deus que nossos dirigentes tenham realm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  ptbr_train_track_a_00001   \n",
       "1  ptbr_train_track_a_00002   \n",
       "2  ptbr_train_track_a_00003   \n",
       "3  ptbr_train_track_a_00004   \n",
       "4  ptbr_train_track_a_00005   \n",
       "\n",
       "                                                text  Anger  Disgust  Fear  \\\n",
       "0  minha vó me disse que era frango e eu comi, ti...      0        0     0   \n",
       "1  Está e a nossa deputada Benedita linda guerrei...      0        0     0   \n",
       "2                     só falta as roupas kkkkkkkkkkk      0        0     0   \n",
       "3  Eu tmb. Comecei a sair de casa agora (fui pela...      0        0     0   \n",
       "4  Peço a Deus que nossos dirigentes tenham realm...      0        0     0   \n",
       "\n",
       "   Joy  Sadness  Surprise  \n",
       "0    0        1         0  \n",
       "1    1        0         0  \n",
       "2    1        0         0  \n",
       "3    0        1         0  \n",
       "4    0        0         0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento dos dados\n",
    "1. Case folding\n",
    "2. Remover stop words\n",
    "3. Remover acentuação e pontuação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'às',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"] = data[\"text\"].copy()\n",
    "# Case folding\n",
    "data[\"clean_text\"] = data[\"clean_text\"].str.lower()\n",
    "# Remover stopwords\n",
    "data[\"clean_text\"] = data[\"clean_text\"].replace({r\"\\b\" + stopword + r\"\\b\": \"\" for stopword in stopwords}, regex=True)\n",
    "# Remover acentuação e pontuação\n",
    "data[\"clean_text\"] = data[\"clean_text\"].str.replace(r\"[\\.!?\\\\\\-.,]\", \"\", regex=True)\n",
    "data[\"clean_text\"] = data[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       minha vó me disse que era frango e eu comi, ti...\n",
       " 1       Está e a nossa deputada Benedita linda guerrei...\n",
       " 2                          só falta as roupas kkkkkkkkkkk\n",
       " 3       Eu tmb. Comecei a sair de casa agora (fui pela...\n",
       " 4       Peço a Deus que nossos dirigentes tenham realm...\n",
       "                               ...                        \n",
       " 2221              Eu acho que o CAP vai surpreender hein.\n",
       " 2222    23:59 - Lula sabia de toda a corrupção no seu ...\n",
       " 2223    O Brasil precisa URGENTE de pessoas sérias e c...\n",
       " 2224    Sera que só eu acho que ta passando da hora de...\n",
       " 2225                                     falta só 2 porra\n",
       " Name: text, Length: 2226, dtype: object,\n",
       " 0         vó disse frango comi gosto frango mto inocente \n",
       " 1        deputada benedita linda guerreira parabéns ju...\n",
       " 2                                falta roupas kkkkkkkkkkk\n",
       " 3        tmb comecei sair casa agora ( primeira vez ci...\n",
       " 4       peço deus dirigentes realmente iluminação toma...\n",
       "                               ...                        \n",
       " 2221                        acho cap vai surpreender hein\n",
       " 2222    23:59 lula sabia toda corrupção governo 00:00 ...\n",
       " 2223     brasil precisa urgente pessoas sérias comprom...\n",
       " 2224    sera acho ta passando hora impeachment pra tir...\n",
       " 2225                                        falta 2 porra\n",
       " Name: clean_text, Length: 2226, dtype: object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"], data[\"clean_text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionar emoção neutra\n",
    "\n",
    "Para casos que não tem nenhuma emoção na linha, adicionamos uma nova emoção: neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_EMOTIONS = [\"Anger\", \"Disgust\", \"Fear\", \"Joy\", \"Sadness\", \"Surprise\"]\n",
    "\n",
    "data[\"Neutral\"] = 0\n",
    "no_emotions_mask = data[BASE_EMOTIONS].sum(axis=1) == 0\n",
    "data.loc[no_emotions_mask, \"Neutral\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "def train_test_val_split(data: pd.DataFrame) -> Union[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    train, test = train_test_split(\n",
    "        data,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    train, val = train_test_split(\n",
    "        train,\n",
    "        test_size=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "    return train, val, test\n",
    "\n",
    "train, val, test = train_test_val_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln-trabalho-final-9al6VtFs-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
